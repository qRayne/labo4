# Labo 04 â€“ Optimization, Caching, Load Balancing, Test de charge, ObservabilitÃ©

<img src="https://upload.wikimedia.org/wikipedia/commons/2/2a/Ets_quebec_logo.png" width="250">    
Ã‰TS - LOG430 - Architecture logicielle - ChargÃ© de laboratoire: Gabriel C. Ullmann, Automne 2025.

## ğŸ¯ Objectifs d'apprentissage
- Apprendre Ã  configurer Prometheus
- Apprendre Ã  effectuer les tests de charge avec [Locust](https://docs.locust.io/en/stable/what-is-locust.html)
- Comprendre les types d'optimisation possibles ainsi que les avantages et inconvÃ©nients de chacun
- Apprendre Ã  implÃ©menter le cache en mÃ©moire avec Redis et l'Ã©quilibrage de charge (load balancing) avec [Nginx](https://nginx.org/en/docs/http/load_balancing.html)

## âš™ï¸ Setup

Dans ce laboratoire, on continuera Ã  utiliser la mÃªme version du Â« store manager Â» dÃ©veloppÃ©e au laboratoire 03, mais nous ferons quelques modifications. Le but n'est pas d'ajouter de nouvelles fonctionnalitÃ©s, mais de mesurer et comparer la performance de lecture/Ã©criture de l'application en utilisant MySQL et Redis. AprÃ¨s avoir mesurÃ© et comparÃ©, nous allons implÃ©menter deux approches d'optimisation : caching et load balancing.

> âš ï¸ **IMPORTANT** : Les documents ARC42 et ADR contenus dans ce dÃ©pÃ´t sont identiques Ã  ceux du laboratoire 03, car nous ne modifions pas l'architecture de l'application dans ce laboratoire.

> ğŸ“ NOTE : Ã€ partir de ce laboratoire, nous vous encourageons Ã  utiliser la bibliothÃ¨que `logging` plutÃ´t que la commande `print`. Bien que `print` fonctionne bien pour le dÃ©bogage, l'utilisation d'un logger est une bonne pratique de dÃ©veloppement logiciel car il offre [plusieurs avantages lorsque notre application entre en production](https://www.geeksforgeeks.org/python/difference-between-logging-and-print-in-python/). Vous trouverez un exemple d'utilisation du `logging` et plus de dÃ©tails dans `src/stocks/commands/write_stock.py`.

### 1. CrÃ©ez un nouveau dÃ©pÃ´t Ã  partir du gabarit et clonez le dÃ©pÃ´t
```bash
git clone https://github.com/[votredepot]/log430-a25-labo4
cd log430-a25-labo4
```

### 2. CrÃ©ez un rÃ©seau Docker
ExÃ©cutez dans votre terminal :
```bash
docker network create labo04-network
```

### 3. PrÃ©parez l'environnement de dÃ©veloppement
Suivez les mÃªmes Ã©tapes que dans le laboratoire dÃ©rnier.

### 4. Installez Postman
Suivez les mÃªmes Ã©tapes que dans le laboratoire dÃ©rnier. Importez la collection disponible dans `/docs/collections`.

### 5. PrÃ©parez lâ€™environnement de dÃ©ploiement et le pipeline CI/CD
Utilisez les mÃªmes approches qui ont Ã©tÃ© abordÃ©es lors des laboratoires dÃ©rniers.

## ğŸ§ª ActivitÃ©s pratiques
Pendant le labo 02, nous avons implÃ©mentÃ© le cache avec Redis. Pendant le labo 03, nous avons utilisÃ© ce cache pour les endpoints des rapports. Dans ce labo, nous allons temporairement dÃ©sactiver le Redis pour mesurer la diffÃ©rence entre les lectures directement de MySQL vs Redis. Pour faciliter les comparaisons, dans ce laboratoire les mÃ©thodes qui font la gÃ©nÃ©ration de rapport dans `queries/read_order.py` ont 2 versions : une pour MySQL, autre pour Redis.

### 1. DÃ©sactivez le cache Redis temporairement
Dans `queries/read_order.py`, remplacez l'appel Ã  `get_highest_spending_users_redis` par `get_highest_spending_users_mysql`. Ã‰galement, remplacez l'appel Ã  `get_best_selling_products_redis` par `get_best_selling_products_mysql`.

### 2. Instrumentez Flask avec Prometheus
Dans `store_manager.py`, ajoutez un endpoint `/metrics`, qui permettra Ã  Prometheus de lire l'Ã©tat des variables que nous voulons observer dans l'application.
```python
@app.route("/metrics")
def metrics():
    return generate_latest(), 200, {"Content-Type": CONTENT_TYPE_LATEST}
```

N'oubliez pas d'ajouter Ã©galement les `imports` suivants:
```python
from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST
```

### 3. CrÃ©ez des Counters 
Ã‰galement dans `store_manager.py`, ajoutez les objets [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) pour compter le nombre de requÃªtes aux endpoints `/orders`, `/orders/reports/highest-spenders` et `/orders/reports/best-sellers`. N'oubliez pas d'appeler la mÃ©thode `inc()` pour incrÃ©menter la valeur du compteur Ã  chaque requÃªte. Par exemple :

```python
counter_orders = Counter('orders', 'Total calls to /orders')
@app.post('/orders')
def post_orders():
    counter_orders.inc()
```

Reconstruisez et puis redÃ©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

### 4. Observez les mÃ©triques dans Prometheus
Dans Postman, faites quelques requÃªtes Ã  `POST /orders`. Ensuite, accÃ©dez Ã  Prometheus sur `http://localhost:9090` et exÃ©cutez une requÃªte (query) Ã  `orders_total`. Vous devriez voir une valeur numÃ©rique associÃ©e Ã  la variable. Faites la mÃªme chose pour les deux autres `Counters`. Par exemple, si vous avez nommÃ© le compteur `highest_spenders`, exÃ©cutez une requÃªte Ã  `highest_spenders_total`. Cliquez sur `Graph` pour voir la reprÃ©sentation visuelle de chaque variable. Faites quelques requÃªtes de plus pour voir le changement des variables.

> ğŸ“ **NOTE** : Prometheus ne met pas automatiquement Ã  jour les variables dans l'interface Web lorsqu'elles changent dans le serveur. Vous devez cliquer sur `Query` ou recharger la page Web pour voir les valeurs mises Ã  jour.

### 5. Lancez un test de charge avec Locust
Le script `locustfiles/locustfile.py` lorsqu'il est exÃ©cutÃ©, effectuera plusieurs appels vers des endpoints (reprÃ©sentÃ©s par les mÃ©thodes `@task`), simulant ainsi des utilisateurs rÃ©els. Dans un premier temps, nous ne modifierons pas ce script, nous l'activerons simplement Ã  partir de l'interface web Ã  Locust.

AccÃ©dez Ã  `http://localhost:8089` et appliquez les paramÃ¨tres suivantes :
- Number of users (nombre d'utilisateurs) : 100
- Spawn rate (taux d'apparition des nouveaux utilisateurs) : 1 (par seconde)

Lancez le test et observez les statistiques et graphiques dans Locust (onglet `Charts`). En un peu moins de 2 minutes, vous devriez observer que votre application reÃ§oit une charge de requÃªtes Ã©quivalente Ã  100 utilisateurs simultanÃ©s.

> ğŸ’¡ **Question 1** : Quelle est la latence moyenne (50Ã¨me percentile) et le taux d'erreur observÃ©s avec 100 utilisateurs ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust (onglet `Charts`).

### 6. Ã‰crivez un nouveau test de charge avec Locust
Dans le rÃ©pertoire `locustfiles/experiments/locustfile_read_write.py`, complÃ©tez le script `locustfile_read_write.py` pour ajouter une commande en utilisant des valeurs alÃ©atoires et une proportion d'exÃ©cution des mÃ©thodes `@task` Ã  66% lectures, 33% Ã©critures (2/3, 1/3, 1/3). Plus d'informations sur la proportion d'exÃ©cution des appels de chaque mÃ©thode `@task` [dans la documentation officielle Ã  Locust](https://docs.locust.io/en/stable/writing-a-locustfile.html#task-decorator).

Finalement, copiez le code modifiÃ© de `locustfiles/experiments/locustfile_read_write.py` Ã  `locustfiles/locustfile.py`. Reconstruisez et puis redÃ©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```
Relancez les tests Locust avec les mÃªmes paramÃ¨tres de la derniÃ¨re activitÃ©. Si cela fonctionne, passez Ã  l'activitÃ© 7.

### 7. Augmentez la charge
Augmentez progressivement le nombre d'utilisateurs jusqu'Ã  ce que l'application Ã©choue (par exemple, jusqu'Ã  obtenir une quantitÃ© importante d'erreurs 500, de timeouts, etc.). Regardez l'onglet `Failures` pour plus d'informations sur les erreurs.

> ğŸ’¡ **Question 2** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec MySQL) ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust.

### 8. Optimisez la lecture des donnÃ©es des articles
Avant d'envisager un changement de base de donnÃ©es, de serveur Web ou une augmentation des ressources matÃ©rielles (RAM/CPU) sur notre serveur on-premises ou en nuage, il est raisonnable de vÃ©rifier si une optimisation du code existant est possible. Cette approche prÃ©sente gÃ©nÃ©ralement le meilleur rapport coÃ»t-efficacitÃ©.

Dans `orders/commands/write_order.py`, si nous regardons attentivement la fonction `add_order`, nous verrons qu'elle ne rÃ©cupÃ¨re pas les informations des articles de maniÃ¨re efficace. Si nous avions, par exemple, 100 articles dans notre commande, la fonction effectuerait 100 requÃªtes Ã  la base de donnÃ©es pour chercher les informations sur les articles ([problÃ¨me N+1](https://planetscale.com/blog/what-is-n-1-query-problem-and-how-to-solve-it)). Ã€ fur et a mesure que le nombre d'articles augmente dans la base, le temps de recherche augmente Ã©galement.

```python
# âŒ Code non-optimisÃ©
product_prices = {}
for product_id in product_ids:
    product = session.query(Product).filter(Product.id == product_id).all()
    product_prices[product_id] = product[0].price
```

Modifiez la mÃ©thode `add_order` de faÃ§on Ã  collecter et rÃ©cupÃ©rer tous les `product_ids` en une seule requÃªte. Nous utiliserons toujours une boucle `for`, mais la requÃªte de base de donnÃ©es **ne se trouve pas dans la boucle**.
```python
# âœ… Code optimisÃ©
product_prices = {}
product_ids = [1, 2, 3] # Collectez le product_id de chaque OrderItem
products = session.query(Product).filter(Product.id.in_(product_ids)).all()
for product in products:
    product_prices[product.id] = product.price
```

> ğŸ“ NOTE : Ceci n'est qu'un exemple trivial d'optimisation de lecture. Dans une application rÃ©elle, il faut parfois effectuer des ajustements plus granulaires dans la base de donnÃ©es, comme la [crÃ©ation d'index](https://www.w3schools.com/mysql/mysql_create_index.asp) et la [normalisation](https://www.ibm.com/fr-fr/think/topics/database-normalization). Nous pouvons Ã©galement augmenter le [nombre de connexions disponibles dans MySQL](https://dev.mysql.com/doc/refman/8.4/en/server-system-variables.html#sysvar_max_connections). Il ne s'agit pas vraiment d'une optimisation, mais plutÃ´t d'une solution provisoire.

Reconstruisez et puis redÃ©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

Relancez les tests Locust avec les mÃªmes paramÃ¨tres de la derniÃ¨re activitÃ©.

> ğŸ’¡ **Question 3** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec MySQL + optimisation) ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust.

### 9. RÃ©activez Redis
Dans `queries/read_order.py`, remplacez l'appel Ã  `get_highest_spending_users_mysql` par `get_highest_spending_users_redis`. Ã‰galement, remplacez l'appel Ã  `get_best_selling_products_mysql` par `get_best_selling_products_redis`.

Cependant, avant de relancer les tests, nous devons optimiser la gÃ©nÃ©ration des rapports. MÃªme si Redis est en mÃ©moire et que l'accÃ¨s est rapide, nous l'interrogeons trÃ¨s frÃ©quemment pour obtenir la liste de commandes (`r.keys("order:*")`), puis nous parcourons cette liste, rÃ©cupÃ©rons l'objet commande (`r.hgetall(key)`) et le traitons pour gÃ©nÃ©rer le rapport. Cette approche prend trop de temps, et la durÃ©e nÃ©cessaire augmente proportionnellement avec la quantitÃ© de commandes et d'articles par commande. Pour rÃ©soudre ce problÃ¨me, nous devons conserver le rapport en cache pendant une pÃ©riode dÃ©terminÃ©e. Le rapport ne sera dÃ©sormais plus mis Ã  jour en temps rÃ©el, mais cette solution nous permettra de servir des rapports trÃ¨s rÃ©cents de maniÃ¨re quasi instantanÃ©e.

Dans `orders/commands/read_order.py`, Ã  la fin de la mÃ©thode `get_highest_spending_users_redis`, stockez le rapport dans le cache avant de le retourner au contrÃ´leur :
```python
r.hset('reports:highest_spending_users', mapping=result)
r.expire("reports:highest_spending_users", 60) # invalider le cache toutes les 60 secondes
return result
```

Au dÃ©but de la mÃ©thode `get_highest_spending_users_redis`, vÃ©rifiez si le rapport existe dÃ©jÃ  dans le cache. Si c'est le cas, retournez immÃ©diatement l'objet en cache. Sinon, exÃ©cutez les Ã©tapes nÃ©cessaires pour gÃ©nÃ©rer le rapport :
```python
report_in_cache = r.hget("reports:highest_spending_users")
if report_in_cache:
    return json.loads(report_in_cache)
else:
    # Obtenir les clÃ©s des commandes 
    # GÃ©nÃ©rer le rapport 
    # Trier (dÃ©croissant), limite X
    return result
```

Ã‰galement, appliquez cette optimisation au rapport `best_selling_products`.

### 10. Testez la charge encore une fois
Reconstruisez et puis redÃ©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

Relancez les tests Locust avec les mÃªmes paramÃ¨tres de la derniÃ¨re activitÃ©. Si nÃ©cessaire, augmentez progressivement le nombre d'utilisateurs jusqu'Ã  ce que l'application Ã©choue.

> ğŸ’¡ **Question 4** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec Redis + optimisation) ? Quelle est la latence et le taux d'erreur observÃ©s ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust.

### 11. Testez l'Ã©quilibrage de charge (load balancing) avec Nginx
Pour tester le scÃ©nario suivant, utilisez le rÃ©pertoire `load-balancer-config` :
- Copiez le texte dans `docker-compose-to-copy-paste.txt` et collez-le dans `docker-compose.yml`
- CrÃ©ez un fichier `nginx.conf` dans le rÃ©pertoire racine du projet.
- Copiez le texte dans `nginx-conf-to-copy-paste.txt` et collez-le dans un fichier `nginx.conf`
Observez les modifications apportÃ©es Ã  `docker-compose.yml`. Ensuite, reconstruisez et puis redÃ©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

Relancez les tests Locust avec les mÃªmes paramÃ¨tres de la derniÃ¨re activitÃ©.

> ğŸ’¡ **Question 5** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec Redis + Optimisation + Nginx load balancing) ? Quelle est la latence moyenne (50Ã¨me percentile) et le taux d'erreur observÃ©s ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust.

> ğŸ’¡ **Question 6** : Avez-vous constatÃ© une amÃ©lioration des performances Ã  mesure que nous avons mis en Å“uvre diffÃ©rentes approches d'optimisation ? Quelle a Ã©tÃ© la meilleure approche ? Justifiez votre rÃ©ponse en vous rÃ©fÃ©rant aux rÃ©ponses prÃ©cÃ©dentes.

> ğŸ’¡ **Question 7** : Dans le fichier `nginx.conf`, il existe un attribut qui configure l'Ã©quilibrage de charge. Quelle politique d'Ã©quilibrage de charge utilisons-nous actuellement ? Consultez la documentation officielle Nginx si vous avez des questions.

## ğŸ“¦ Livrables

- Un fichier .zip contenant l'intÃ©gralitÃ© du code source du projet Labo 04.
- Un rapport en .pdf rÃ©pondant aux questions prÃ©sentÃ©es dans ce document. Il est obligatoire d'illustrer vos rÃ©ponses avec du code ou des captures d'Ã©cran/terminal.
