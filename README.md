# Labo 04 ‚Äì Optimization, Caching, Load Balancing, Test de charge, Observabilit√©

<img src="https://upload.wikimedia.org/wikipedia/commons/2/2a/Ets_quebec_logo.png" width="250">    
√âTS - LOG430 - Architecture logicielle - Charg√© de laboratoire: Gabriel C. Ullmann, Automne 2025.

## üéØ Objectifs d'apprentissage
- Apprendre √† configurer Prometheus
- Apprendre √† effectuer les tests de charge avec [Locust](https://docs.locust.io/en/stable/what-is-locust.html)
- Comprendre les types d'optimisation possibles ainsi que les avantages et inconv√©nients de chacun
- Apprendre √† impl√©menter le cache en m√©moire avec Redis et l'√©quilibrage de charge (load balancing) avec [Nginx](https://nginx.org/en/docs/http/load_balancing.html)

## ‚öôÔ∏è Setup

Dans ce laboratoire, on continuera √† utiliser la m√™me version du ¬´ store manager ¬ª d√©velopp√©e au laboratoire 03, mais nous ferons quelques modifications. Le but n'est pas d'ajouter de nouvelles fonctionnalit√©s, mais de mesurer et comparer la performance de lecture/√©criture de l'application en utilisant MySQL et Redis. Apr√®s avoir mesur√© et compar√©, nous allons impl√©menter deux approches d'optimisation : caching et load balancing.

> ‚ö†Ô∏è **IMPORTANT** : Les documents ARC42 et ADR contenus dans ce d√©p√¥t sont identiques √† ceux du laboratoire 03, car nous ne modifions pas l'architecture de l'application dans ce laboratoire.

> üìù NOTE : √Ä partir de ce laboratoire, nous vous encourageons √† utiliser la biblioth√®que `logging` plut√¥t que la commande `print`. Bien que `print` fonctionne bien pour le d√©bogage, l'utilisation d'un logger est une bonne pratique de d√©veloppement logiciel car il offre [plusieurs avantages lorsque notre application entre en production](https://www.geeksforgeeks.org/python/difference-between-logging-and-print-in-python/). Vous trouverez un exemple d'utilisation du `logging` et plus de d√©tails dans `src/stocks/commands/write_stock.py`.

### 1. Cr√©ez un nouveau d√©p√¥t √† partir du gabarit et clonez le d√©p√¥t
```bash
git clone https://github.com/[votredepot]/log430-a25-labo4
cd log430-a25-labo4
```

### 2. Cr√©ez un r√©seau Docker
Ex√©cutez dans votre terminal :
```bash
docker network create labo04-network
```

### 3. Pr√©parez l'environnement de d√©veloppement
Suivez les m√™mes √©tapes que dans le laboratoire d√©rnier.

### 4. Installez Postman
Suivez les m√™mes √©tapes que dans le laboratoire d√©rnier. Importez la collection disponible dans `/docs/collections`.

### 5. Pr√©parez l‚Äôenvironnement de d√©ploiement et le pipeline CI/CD
Utilisez les m√™mes approches qui ont √©t√© abord√©es lors des laboratoires d√©rniers.

## üß™ Activit√©s pratiques
Pendant le labo 02, nous avons impl√©ment√© le cache avec Redis. Pendant le labo 03, nous avons utilis√© ce cache pour les endpoints des rapports. Dans ce labo, nous allons temporairement d√©sactiver le Redis pour mesurer la diff√©rence entre les lectures directement de MySQL vs Redis. Pour faciliter les comparaisons, dans ce laboratoire les m√©thodes qui font la g√©n√©ration de rapport dans `queries/read_order.py` ont 2 versions : une pour MySQL, autre pour Redis.

### 1. D√©sactivez le cache Redis temporairement
Dans `queries/read_order.py`, remplacez l'appel √† `get_highest_spending_users_redis` par `get_highest_spending_users_mysql`. √âgalement, remplacez l'appel √† `get_best_selling_products_redis` par `get_best_selling_products_mysql`.

### 2. Instrumentez Flask avec Prometheus
Dans `store_manager.py`, ajoutez un endpoint `/metrics`, qui permettra √† Prometheus de lire l'√©tat des variables que nous voulons observer dans l'application.
```python
@app.route("/metrics")
def metrics():
    return generate_latest(), 200, {"Content-Type": CONTENT_TYPE_LATEST}
```

N'oubliez pas d'ajouter √©galement les `imports` suivants:
```python
from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST
```

### 3. Cr√©ez des Counters 
√âgalement dans `store_manager.py`, ajoutez les objets [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) pour compter le nombre de requ√™tes aux endpoints `/orders`, `/orders/reports/highest-spenders` et `/orders/reports/best-sellers`. N'oubliez pas d'appeler la m√©thode `inc()` pour incr√©menter la valeur du compteur √† chaque requ√™te. Par exemple :

```python
counter_orders = Counter('orders', 'Total calls to /orders')
@app.post('/orders')
def post_orders():
    counter_orders.inc()
```

Reconstruisez et puis red√©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

### 4. Observez les m√©triques dans Prometheus
Dans Postman, faites quelques requ√™tes √† `POST /orders`. Ensuite, acc√©dez √† Prometheus sur `http://localhost:9090` et ex√©cutez une requ√™te (query) √† `orders_total`. Vous devriez voir une valeur num√©rique associ√©e √† la variable. Faites la m√™me chose pour les deux autres `Counters`. Par exemple, si vous avez nomm√© le compteur `highest_spenders`, ex√©cutez une requ√™te √† `highest_spenders_total`. Cliquez sur `Graph` pour voir la repr√©sentation visuelle de chaque variable. Faites quelques requ√™tes de plus pour voir le changement des variables.

> üìù **NOTE** : Prometheus ne met pas automatiquement √† jour les variables dans l'interface Web lorsqu'elles changent dans le serveur. Vous devez cliquer sur `Query` ou recharger la page Web pour voir les valeurs mises √† jour.

### 5. Lancez un test de charge avec Locust
Le script `locustfiles/locustfile.py` lorsqu'il est ex√©cut√©, effectuera plusieurs appels vers des endpoints (repr√©sent√©s par les m√©thodes `@task`), simulant ainsi des utilisateurs r√©els. Dans un premier temps, nous ne modifierons pas ce script, nous l'activerons simplement √† partir de l'interface web √† Locust.

Acc√©dez √† `http://localhost:8089` et appliquez les param√®tres suivantes :
- Number of users (nombre d'utilisateurs) : 100
- Spawn rate (taux d'apparition des nouveaux utilisateurs) : 1 (par seconde)

Lancez le test et observez les statistiques et graphiques dans Locust (onglet `Charts`). En un peu moins de 2 minutes, vous devriez observer que votre application re√ßoit une charge de requ√™tes √©quivalente √† 100 utilisateurs simultan√©s.

> üí° **Question 1** : Quelle est la latence moyenne (50√®me percentile) et le taux d'erreur observ√©s avec 100 utilisateurs ? Illustrez votre r√©ponse √† l'aide des graphiques Locust (onglet `Charts`).

### 6. √âcrivez un nouveau test de charge avec Locust
Dans le r√©pertoire `locustfiles/experiments/locustfile_read_write.py`, compl√©tez le script `locustfile_read_write.py` pour ajouter une commande en utilisant des valeurs al√©atoires et une proportion d'ex√©cution des m√©thodes `@task` √† 66% lectures, 33% √©critures (2/3, 1/3, 1/3). Plus d'informations sur la proportion d'ex√©cution des appels de chaque m√©thode `@task` [dans la documentation officielle √† Locust](https://docs.locust.io/en/stable/writing-a-locustfile.html#task-decorator).

Finalement, copiez le code modifi√© de `locustfiles/experiments/locustfile_read_write.py` √† `locustfiles/locustfile.py`. Reconstruisez et puis red√©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```
Relancez les tests Locust avec les m√™mes param√®tres de la derni√®re activit√©. Si cela fonctionne, passez √† l'activit√© 7.

### 7. Augmentez la charge
Augmentez progressivement le nombre d'utilisateurs jusqu'√† ce que l'application √©choue (par exemple, jusqu'√† obtenir une quantit√© importante d'erreurs 500, de timeouts, etc.). Regardez l'onglet `Failures` pour plus d'informations sur les erreurs.

> üí° **Question 2** : √Ä partir de combien d'utilisateurs votre application cesse-t-elle de r√©pondre correctement (avec MySQL) ? Illustrez votre r√©ponse √† l'aide des graphiques Locust.

### 8. Optimisez la lecture des donn√©es des articles
Avant d'envisager un changement de base de donn√©es, de serveur Web ou une augmentation des ressources mat√©rielles (RAM/CPU) sur notre serveur on-premises ou en nuage, il est raisonnable de v√©rifier si une optimisation du code existant est possible. Cette approche pr√©sente g√©n√©ralement le meilleur rapport co√ªt-efficacit√©.

Dans `orders/commands/write_order.py`, si nous regardons attentivement la fonction `add_order`, nous verrons qu'elle ne r√©cup√®re pas les informations des articles de mani√®re efficace. Si nous avions, par exemple, 100 articles dans notre commande, la fonction effectuerait 100 requ√™tes √† la base de donn√©es pour chercher les informations sur les articles ([probl√®me N+1](https://planetscale.com/blog/what-is-n-1-query-problem-and-how-to-solve-it)). √Ä fur et a mesure que le nombre d'articles augmente dans la base, le temps de recherche augmente √©galement.

```python
# ‚ùå Code non-optimis√©
product_prices = {}
for product_id in product_ids:
    product = session.query(Product).filter(Product.id == product_id).all()
    product_prices[product_id] = product[0].price
```

Modifiez la m√©thode `add_order` de fa√ßon √† collecter et r√©cup√©rer tous les `product_ids` en une seule requ√™te. Nous utiliserons toujours une boucle `for`, mais la requ√™te de base de donn√©es **ne se trouve pas dans la boucle**.
```python
# ‚úÖ Code optimis√©
product_prices = {}
product_ids = [1, 2, 3] # Collectez le product_id de chaque OrderItem
products = session.query(Product).filter(Product.id.in_(product_ids)).all()
for product in products:
    product_prices[product.id] = product.price
```

> üìù NOTE : Ceci n'est qu'un exemple trivial d'optimisation de lecture. Dans une application r√©elle, il faut parfois effectuer des ajustements plus granulaires dans la base de donn√©es, comme la [cr√©ation d'index](https://www.w3schools.com/mysql/mysql_create_index.asp) et la [normalisation](https://www.ibm.com/fr-fr/think/topics/database-normalization). Nous pouvons √©galement augmenter le [nombre de connexions disponibles dans MySQL](https://dev.mysql.com/doc/refman/8.4/en/server-system-variables.html#sysvar_max_connections). Il ne s'agit pas vraiment d'une optimisation, mais plut√¥t d'une solution provisoire.

Reconstruisez et puis red√©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

Relancez les tests Locust avec les m√™mes param√®tres de la derni√®re activit√©.

> üí° **Question 3** : √Ä partir de combien d'utilisateurs votre application cesse-t-elle de r√©pondre correctement (avec MySQL + optimisation) ? Illustrez votre r√©ponse √† l'aide des graphiques Locust.

### 9. R√©activez Redis
Dans `queries/read_order.py`, remplacez l'appel √† `get_highest_spending_users_mysql` par `get_highest_spending_users_redis`. √âgalement, remplacez l'appel √† `get_best_selling_products_mysql` par `get_best_selling_products_redis`.

Cependant, avant de relancer les tests, nous devons optimiser la g√©n√©ration des rapports. M√™me si Redis est en m√©moire et que l'acc√®s est rapide, nous l'interrogeons tr√®s fr√©quemment pour obtenir la liste de commandes (`r.keys("order:*")`), puis nous parcourons cette liste, r√©cup√©rons l'objet commande (`r.hgetall(key)`) et le traitons pour g√©n√©rer le rapport. Cette approche prend trop de temps, et la dur√©e n√©cessaire augmente proportionnellement avec la quantit√© de commandes et d'articles par commande. Pour r√©soudre ce probl√®me, nous devons conserver le rapport en cache pendant une p√©riode d√©termin√©e. Le rapport ne sera d√©sormais plus mis √† jour en temps r√©el, mais cette solution nous permettra de servir des rapports tr√®s r√©cents de mani√®re quasi instantan√©e.

Dans `orders/commands/read_order.py`, √† la fin de la m√©thode `get_highest_spending_users_redis`, stockez le rapport dans le cache avant de le retourner au contr√¥leur :
```python
r.hset('reports:highest_spending_users', mapping=result)
r.expire("reports:highest_spending_users", 60) # invalider le cache toutes les 60 secondes
return result
```

Au d√©but de la m√©thode `get_highest_spending_users_redis`, v√©rifiez si le rapport existe d√©j√† dans le cache. Si c'est le cas, retournez imm√©diatement l'objet en cache. Sinon, ex√©cutez les √©tapes n√©cessaires pour g√©n√©rer le rapport :
```python
report_in_cache = r.hget("reports:highest_spending_users")
if report_in_cache:
    return json.loads(report_in_cache)
else:
    # Obtenir les cl√©s des commandes 
    # G√©n√©rer le rapport 
    # Trier (d√©croissant), limite X
    return result
```

√âgalement, appliquez cette optimisation au rapport `best_selling_products`.

### 10. Testez la charge encore une fois
Reconstruisez et puis red√©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

Relancez les tests Locust avec les m√™mes param√®tres de la derni√®re activit√©. Si n√©cessaire, augmentez progressivement le nombre d'utilisateurs jusqu'√† ce que l'application √©choue.

> üí° **Question 4** : √Ä partir de combien d'utilisateurs votre application cesse-t-elle de r√©pondre correctement (avec Redis + optimisation) ? Quelle est la latence et le taux d'erreur observ√©s ? Illustrez votre r√©ponse √† l'aide des graphiques Locust.

### 11. Testez l'√©quilibrage de charge (load balancing) avec Nginx
Pour tester le sc√©nario suivant, utilisez le r√©pertoire `load-balancer-config` :
- Copiez le texte dans `docker-compose-to-copy-paste.txt` et collez-le dans `docker-compose.yml`
- Cr√©ez un fichier `nginx.conf` dans le r√©pertoire racine du projet.
- Copiez le texte dans `nginx-conf-to-copy-paste.txt` et collez-le dans un fichier `nginx.conf`
Observez les modifications apport√©es √† `docker-compose.yml`. Ensuite, reconstruisez et puis red√©marrez le conteneur Docker.
```bash
docker compose down -v && docker compose up -d --build                     
```

Relancez les tests Locust avec les m√™mes param√®tres de la derni√®re activit√©.

> üí° **Question 5** : √Ä partir de combien d'utilisateurs votre application cesse-t-elle de r√©pondre correctement (avec Redis + Optimisation + Nginx load balancing) ? Quelle est la latence moyenne (50√®me percentile) et le taux d'erreur observ√©s ? Illustrez votre r√©ponse √† l'aide des graphiques Locust.

> üí° **Question 6** : Avez-vous constat√© une am√©lioration des performances √† mesure que nous avons mis en ≈ìuvre diff√©rentes approches d'optimisation ? Quelle a √©t√© la meilleure approche ? Justifiez votre r√©ponse en vous r√©f√©rant aux r√©ponses pr√©c√©dentes.

> üí° **Question 7** : Dans le fichier `nginx.conf`, il existe un attribut qui configure l'√©quilibrage de charge. Quelle politique d'√©quilibrage de charge utilisons-nous actuellement ? Consultez la documentation officielle Nginx si vous avez des questions.

## üì¶ Livrables

- Un fichier .zip contenant l'int√©gralit√© du code source du projet Labo 04.
- Un rapport en .pdf r√©pondant aux questions pr√©sent√©es dans ce document. Il est obligatoire d'illustrer vos r√©ponses avec du code ou des captures d'√©cran/terminal.
